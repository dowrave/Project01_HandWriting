# 시행착오 겪는 일종의 일기장입니다

# 이 프로젝트의 목표
1. MNIST 손글씨 데이터셋을 이용, openCV로 만든 일종의 그림판에 글씨를 쓰고 spacebar를 입력받으면 텐서플로우 모델이 가장 높은 확률을 갖는 글씨 출력 (`main1 폴더`) <b>[완]</b>
    - 모델은 구글 코랩에서 만들고 `model.save`로 `h5`파일을 가져옴.
2. 1.을 구현한 다음, 한글 혹은 일본어로 새로 모델을 학습시킬 계획

    ## 220628
    1. MNIST 모델 - INPUT에 다양한 변화를 주며 훈련시키기 (완)
    - 데이터 증강 층만 추가한 `model_220628.h5` 학습 (`RandomZoom`, `RandomRotation` 층 모델에 추가)
    - 원래는 MNIST 이미지를 `100*100`으로 Resizing해서 학습시키려 했으나, 코랩에서 OOM(GPU 메모리 부족) 에러가 뜨기도 했고, 검색 결과 "이미지 확대를 굳이 해야 됨?"이라는 의견과 "이미지 확대는 추가적인 정보를 얻지 못하면서도 요구 메모리가 증가함"이라는 의견을 접했음.
    2. 한글 or 일본어 손글씨 추론 모델 만들기


    ## 220627
    1. 출력할 때 확률이 높은 3개 출력하기
        - `np.argsort()` 라니.. 누가 알았겠는가? (몇 시간 헤멤) 역시 라이브러리 문서가 최고다.
        
        ### 앞으로 할 일
            1. 모델 재훈련 : 글씨가 작아지는 경우도 잘 파악해야 하지 않을까..
            2. 한글, 일본어(가나, 한자?)로 넘어가기로 한다.

    ## 220624
    1. 구현 자체는 성공했으나, 모델의 필기체 인식 성능이 매우 떨어짐

        ### 예측 성능에 관한 분석
        - 짐작 가는 오류 원인은 2가지가 있다.
        - 1. mnist 이미지는 28 * 28인데, 그림판은 100 * 100을 만든 뒤 28 * 28로 축소하는 방식임 : 손실되는 정보가 있을 것
        - 2. mnist 이미지의 배경은 흑색, 글씨는 백색인데 그림판의 배경은 백색, 글씨는 흑색임
        - 실제로 테스트해보니, (체감상) 크기도 영향이 있지만, 색상이 오류에 기여하는 바가 더 커보임
    
    2. 모델 재훈련(`model_220624.h5`)
        - 인풋 데이터의 배경색과 글자 색만 반전, 크기는 `28 * 28` 유지함
        - 실행 결과 글씨가 화면을 꽉 채울 정도가 되면 잘 인식함
        - 한편 크기가 어느 정도 작다면 출력에 오류가 있는 경우가 많음
        - 이는 그림판에 그린 손글씨를 축소시켜서 추론 모델에 넣는 과정에서 정보들이 사라지는 것으로 보임

        ### (앞으로 할 거)
        1. 출력할 때 확률이 높은 순서대로 3개만 출력
        2. 모델에 넣는 데이터들에 여러 번형 주기

