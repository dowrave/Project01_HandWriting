# 프로젝트 진행 과정

# 이 프로젝트의 목표
1. MNIST 손글씨 데이터셋을 이용, openCV로 만든 일종의 그림판에 글씨를 쓰고 spacebar를 입력받으면 텐서플로우 모델이 가장 높은 확률을 갖는 글씨 출력 (`main1 폴더`) <b>[완]</b>
    - 모델은 구글 코랩에서 만들고 `model.save`로 `h5`파일을 가져옴.
2. 1.을 구현한 다음, 한글 혹은 일본어로 새로 모델을 학습시킬 계획 (`main2 폴더`) <b> 진행 중 </b>
    - (220701 이후) 모델, 데이터는 모두 가져올 예정
        - 모델 :[이 논문](https://scienceon.kisti.re.kr/commons/util/originalView.do?cn=JAKO201823955287871&oCn=JAKO201823955287871&dbt=JAKO&journal=NJOU00292001)
        - 데이터 : [PHD08](https://www.dropbox.com/s/69cwkkqt4m1xl55/phd08.alz?dl=0)
            - [데이터 개요](https://www.kci.go.kr/kciportal/ci/sereArticleSearch/ciSereArtiView.kci?sereArticleSearchBean.artiId=ART001293992)

    - 사용해봤으나 실제로 쓰이지 않는 글자가 많고 각 글자의 데이터도 적어서 X
        - [ai 허브](https://aihub.or.kr/aidata/133)
    - 별도의 확장자명으로 저장이 되어 있는데, 파이썬 & 바이너리로 정보를 뽑아내는 방법을 몰라서 사용 X
        - DB : [PE92](https://github.com/callee2006/HangulDB)
            - [PE92 소개서](https://www.koreascience.or.kr/article/CFKO199229013564134.pdf)

3. 프로젝트 끝나면 ppt로 정리

# 진행 과정

## 220702 
1. 넘파이 데이터 불러와 메모리에 올리기 (완) & 넘파이 파일 구글 드라이브에 저장
    - `np.concatenate` 시도 : 4만개 넘어가니까 확 느려짐
        - 검색 결과 : arr 기반 알고리즘의 `resize`가 일어나면, 내부의 모든 요소를 복사해야 함
        - 전체 array 사이즈를 알 수 있기 때문에 `np.empty((size), dtype)`으로 미리 arr을 넣고 값을 넣는 방식으로 해결
        - 생각보다 빠름
    - 참고 : `plt.imshow()`는 `np.float16`에서 사용이 안된다 (버그인지는 몰?루)
        - 그래서 `plt.imshow()`로 시각화하고 싶다면 해당 array를 `np.array(arr, dtype=np.float32)`를 넣어서 확인할 것
2. `minmaxscaler` 적용 (완)


## 앞으로 할 일
- GoogleNet은 참고할 예정이니까 유지, phd08 데이터들도 깃허브에서 받은 프로그램으로 변환 완료.
- 넘파이 배열은 -값을 갖거나 1을 넘는 값이 넘는 경우도 있음. `minmaxscaler` 참고하자.

## 220701
1. 모델 만들기 (2) : (코랩에서 진행) csv 파일을 이용해 모델 생성
    - 시각화했을 때 각 글자는 7 ~ 13개가 있는 듯 보였으나... 1개 있는 글자도 있다. 아..
    - 교훈 ) 본격적인 프로젝트 시작 전에 데이터부터 파악해둘 필요가 있다.
    - Stratify를 위해 <b>데이터 갯수가 5개보다 적다면 제외</b>하겠음 (완료)
    - 좋은 성능을 기대하기는 힘들어진 것 같고, 일단 모델을 완성해서 적용하는 것까지 구현해보자
    - 구현에 의의를 두기로 했으나...

2. 전처리들 끝내고(LabelEncoder, Pandas(`.apply` 등..)) `main1.py`에서 했던 모델을 거의 그대로 가져오고 마지막 분류 층의 노드 수만 11117개로 늘렸으나 학습률이 절망적임 (0.0001 수준)
    - <b>모델과 데이터 모두 바꿀 필요성</b>이 있어 보임
    - 모델은 [이 논문](https://scienceon.kisti.re.kr/commons/util/originalView.do?cn=JAKO201823955287871&oCn=JAKO201823955287871&dbt=JAKO&journal=NJOU00292001)을 참고할 예정
    - DB는 [PE92](https://www.koreascience.or.kr/article/CFKO199229013564134.pdf)을 볼 예정이었으나

3. DB가 `hdu1` 확장자명으로 저장되어 있는데 이걸 파이썬에 담을 수가 없었다(`UTF-8`, `CP949` 코덱 모두 디코드에러가 뜸)
    - 바이너리로 읽은 뒤 `\OOO` 값이나 `\OO`값을 `decode()` 메소드나 `list()`에 담아서 볼 수 있었는데, 아무래도 별도의 방법이 필요한 듯 함(리스트에 담은 뒤 16 * 16으로 `np.reshape`를 해봤으나 글자가 아니라 이상한 모양이 나옴)

4. 그래서 다른 DB인 `phd08`을 사용, 텍스트 파일로 저장되어 있다.
    - 이걸 누군가가 넘파이 혹은 png 파일로 자동으로 저장할 수 있게 [프로그램](https://github.com/sungjunyoung/phd08-conversion)을 짜 둔게 있었다. 
    - 단 2017년에 올라온 코드라 더 이상 지원하지 않는 함수 `scipy.misc.imresize`가 있어서, 이를 `np.array(PIL.Image.fromarray(arr).resize()` 함수로 바꿔서 사용했다.
    - 이 데이터를 `15 * 15`로 바꿔서 넘파이로 저장해서 사용할 예정이다. 넘파이로 잘 불러와지는지까지 확인하고 오늘은 마무리할 예정.

## 220629
1. 모델 만들기 (1) : json 파일 & 이미지 파일 -> csv 파일로 저장
    - 픽셀의 각 값을 별도의 column으로 해서 저장하는 게 낫지 않을까.. 그렇게 분리해서 csv 파일에 저장할 수 있을 듯
    - 아예 정규화까지 해버리는 것도 좋을 듯?


## 220628
1. MNIST 모델 - INPUT에 다양한 변화를 주며 훈련시키기 (완)
- 데이터 증강 층만 추가한 `model_220628.h5` 학습 (`RandomZoom`, `RandomRotation` 층 모델에 추가)
- 원래는 MNIST 이미지를 `100*100`으로 Resizing해서 학습시키려 했으나, 코랩에서 OOM(GPU 메모리 부족) 에러가 뜨기도 했고, 검색 결과 "이미지 확대를 굳이 해야 됨?"이라는 의견과 "이미지 확대는 추가적인 정보를 얻지 못하면서도 요구 메모리가 증가함"이라는 의견을 접했음.

2. 한글 or 일본어 손글씨 추론 모델 만들기
- 일단 json 파일 파싱해서 손글씨 + 음절 데이터를 추리는 것 까지는 성공함 (dict에 저장 : `example_json_parsing.py`)

    ### 앞으로 할 일
    - 이미지 크기가 제각각임 : 통일 시켜줄 필요가 있음
        - `100 * 100` 시도해보고, 메모리가 안된다 싶으면 이미지 크기를 더 낮춰서 진행.
    - dict의 key는 파일(`image_id`), value는 target 값임(해당 이미지가 나타내는 글자)
    - 이걸로 모델 만들어서 분류시키면 될듯

## 220627
1. 출력할 때 확률이 높은 3개 출력하기
    - `np.argsort()` 라니.. 누가 알았겠는가? (몇 시간 헤멤) 역시 라이브러리 문서가 최고다.
    
    ### 앞으로 할 일
        1. 모델 재훈련 : 글씨가 작아지는 경우도 잘 파악해야 하지 않을까..
        2. 한글, 일본어(가나, 한자?)로 넘어가기로 한다.

## 220624
1. 구현 자체는 성공했으나, 모델의 필기체 인식 성능이 매우 떨어짐

    ### 예측 성능에 관한 분석
    - 짐작 가는 오류 원인은 2가지가 있다.
    - 1. mnist 이미지는 28 * 28인데, 그림판은 100 * 100을 만든 뒤 28 * 28로 축소하는 방식임 : 손실되는 정보가 있을 것
    - 2. mnist 이미지의 배경은 흑색, 글씨는 백색인데 그림판의 배경은 백색, 글씨는 흑색임
    - 실제로 테스트해보니, (체감상) 크기도 영향이 있지만, 색상이 오류에 기여하는 바가 더 커보임

2. 모델 재훈련(`model_220624.h5`)
    - 인풋 데이터의 배경색과 글자 색만 반전, 크기는 `28 * 28` 유지함
    - 실행 결과 글씨가 화면을 꽉 채울 정도가 되면 잘 인식함
    - 한편 크기가 어느 정도 작다면 출력에 오류가 있는 경우가 많음
    - 이는 그림판에 그린 손글씨를 축소시켜서 추론 모델에 넣는 과정에서 정보들이 사라지는 것으로 보임

    ### (앞으로 할 거)
    1. 출력할 때 확률이 높은 순서대로 3개만 출력
    2. 모델에 넣는 데이터들에 여러 번형 주기

