# 프로젝트 진행 과정

# 이 프로젝트의 목표
1. MNIST 손글씨 데이터셋을 이용, openCV로 만든 일종의 그림판에 글씨를 쓰고 spacebar를 입력받으면 텐서플로우 모델이 가장 높은 확률을 갖는 글씨 출력 (`main1 폴더`) <b>완</b>
    - 모델은 구글 코랩에서 만들고 `model.save`로 `h5`파일을 가져옴.
2. 1.을 구현한 다음, 한글 혹은 일본어로 새로 모델을 학습시킬 계획 (`main2 폴더`) <b> 완(성능은 불만족) </b>
    - (220701 이후) 모델, 데이터는 모두 가져올 예정
        - 모델 :[논문1](https://scienceon.kisti.re.kr/commons/util/originalView.do?cn=JAKO201823955287871&oCn=JAKO201823955287871&dbt=JAKO&journal=NJOU00292001)과 [논문2](https://scienceon.kisti.re.kr/commons/util/originalView.do?cn=JAKO201630762630914&oCn=JAKO201630762630914&dbt=JAKO&journal=NJOU00431883)를 참고함.
        - 데이터 : 손글씨는 아니고 폰트이지만 가져옴
            - [PHD08](https://www.dropbox.com/s/69cwkkqt4m1xl55/phd08.alz?dl=0)
            - [데이터 개요](https://www.kci.go.kr/kciportal/ci/sereArticleSearch/ciSereArtiView.kci?sereArticleSearchBean.artiId=ART001293992)

### 쓰려다 못 쓴 데이터
- 사용해봤으나 실제로 쓰이지 않는 글자가 많고 각 글자의 데이터도 적어서 X
    - [ai 허브](https://aihub.or.kr/aidata/133)
- 별도의 확장자명으로 저장이 되어 있는데, 파이썬 & 바이너리로 정보를 뽑아내는 방법을 몰라서 사용 X
    - DB : [PE92](https://github.com/callee2006/HangulDB)
        - [PE92 소개서](https://www.koreascience.or.kr/article/CFKO199229013564134.pdf)
        

# 참고
- 모델을 생성하는 파일은 파이썬 파일로만 같이 저장(`model_date.py`)하고 있음. 코랩에서 실행함
- 깃허브에 모델 파일은 용량이 커서 올리지 않는 걸로..

# 진행 과정

## 220708

### 1. `2350 * 81 * 60 * 60` 모델 학습
    - 폰트당 데이터가 9개라 그런가 학습이 매우 더딤
    - 근데 코랩 메모리에 못 올려서 그냥 원본 데이터(단일폰트 50개 `60*60`)까지 하고 프로젝트 마무리

## 220707

### 1. 모델 다시 만들고 실성능 테스트[완]
- 어떻게 구성할 지 고민임
1. 모델 : `이진화, RandomZoom, RandomRotation` 적용할 예정 [완]
2. 그림판 : 텍스트가 써진 영역만 잘라서 추론 모델에 넣는 것도 생각해볼 수 있겠다

- 일단 1부터 진행 : `이진화, RandomZoom 추가` / `RandomRotation은 제외` (원본 데이터가 -3, 0, 3도 회전되어 있음)
    - `RandomZoom 층`을 케라스 레이어로 구현하고, 이진화는 Zoom 이후에 진행(Zoom 과정에서 Interpolation이 일어나기 때문에)
        - 근데 `RandomZoom` 값이 양수일 때 작아지는 거였네? 음수일 때 작아지는 건줄..

### 결과 : 이전보다는 눈에 띄게 좋아짐 (`korean_model_220707.h5`)
- 그래도 복잡한 자음이나, 받침이 있는 글자 등에서 여전히 혼선이 있음

### 2. 인풋 데이터 재구성[완]
- `phd08`은 글자 당 9종류의 폰트로 이루어졌다
    - 글자 크기 3가지(12, 13 ,14)
    - 노이즈 레벨 3가지 (원본, 1회 복사, 2회 복사)
    - 스캔 해상도 3가지(200, 240, 280)
    - 이진화 3가지(140, 180, 220)
    - 회전 3가지(-3, 0, 3도)
    - 글자당 `3^5 * 9 = 2187`개의 샘플이 있음
- 지금까지 해온 데이터는 앞에서부터 50개만 뽑았기 때문에 폰트가 모두 동일하다
    - 즉 한 종류의 폰트에 대해 학습했기 때문에 다른 형태의 폰트가 온다면 제대로 예측하지 못할 가능성이 높아진다
        - 애초에 손글씨니까 폰트라고 할 수는 없고, 그럼에도 `다양한 폰트를 학습해야 한다`는 건 변하지 않음
    - 딱히 변수로 넣지 않는 케이스들 : `노이즈 레벨, 스캔 해상도, 이진화`
        - `60*60`으로 이미지를 확대하는 과정에서 어차피 다시 한 번 만져줘야 하기 때문
        - 코랩 램의 한계때문에 가장 눈에 띄는 특징들인 `글자 크기 3가지와 회전 3가지`만 이용하자 
            - 폰트가 9개니까 한 글자당 81개의 이미지를 사용하는 셈
- 데이터 재구성 완료
    - `phd08_to_npy.py` 파일 수정
        - `FO_FS_0_2_1_SL` 형태(폰트 9가지, 글자 크기 3가지, 기울기 3가지)인 데이터만 뽑아냄
        - 정규식 `("[A-Z0-9]+_[0-2]_0_2_1_[0-2]")` 으로 추려냄 : 넘파이 파일 하나당 `81 * 60 * 60`의 shape를 가진다.

### 3. 도화지 크기 키우고 글씨 영역만 잘라서 추론 모델에 전달하려 했으나 Fail
- `opencv`의 `findContour` 기능을 이용해봤으나, 글자 영역 전체에 윤곽선이 씌워지지 않는 경우가 더 많았음
- `태서렉트`라는 OCR 기능이 있는 프레임워크(?)도 있으나, 그걸 쓰면 이 프로젝트를 하는 의미가 없다고 여겨서 그걸 쓰진 않겠음
- 따라서 도화지 크기는 키우되 그냥 크기만 축소해서 추론 모델에 전달하는 방식으로 마무리 하겠음


## 220706
### 1. 모델 만들기(실험) [완]
- 원래 코드의 `GlobalAveragePooling2D`를 수정 (`avgpooling2D(7*7/1,), 패딩 x`)
- 테스트 : 뭐가 원인이었는지 (궁금하니까 한다)
    - 원인 후보들
    1. 원래 논문의 stem 부분인 (`convolution, batch_normalization, ReLU, max_pool`)을 `convolution(relu) - max_pool - batch_normalization`으로 수정함)
    2. `Inception` 모듈 수가 9개인데, 이거 수를 5개로 줄임
    3. 마지막 분류 층 구성 : 논문은 `avgpooling2D (7*7/1) - Dropout(0.4) - Flatten - Dense(2350)` 으로 하라고 했는데, 이걸 다른 논문에서 가져온 `avgpooling - conv2D(128, (1,1)) -  Dense(1024) - Dropout(0.4) - Dense(2350)` 인지

- 실험 (개선 없음은 1, 2 에포크에서 정확도가 모두 `1e-4~1e-5` 단위)
    - 1. `입력층` 구성을 다르게  : 1 에포크 동안 큰 개선은 없었음
    - 2. `Inception 모듈 수`만 줄여봄 : 큰 개선 없었음
    - 3. `출력층` 구성만 다르게  :  큰 개선 없었음
        - 3-1. 출력층 구성에서, `avgpooling2D` 뒤에 `conv2D(128, (1,1))`을 넣어봄 : 시간은 엄청 증가했는데, 성능 향상은 딱히?
    - 4. Inception 모듈 수 유지(9) / `입력 & 출력층`만 변경 : 역시 큰 개선 없음
    - 5. 입력층 유지, `Inception 수 감소 & 출력층` 변경 : 마찬가지
    - 6. `입력층 변경 & Inception 수 감소` : 눈에 띄게 좋음(<b>에포크 2 검증 정확도 0.9847</b>)
- 모델은 상태 6으로 학습함(실험에 쓰인 다른 상태들은 모두 주석 처리)
    - 왜 다른 건지 알 요량은 없고 경험적으로 가장 좋은 상태로 학습
- 어제 진행한 모델보다 나은 점이라면 학습하는 파라미터 수가 300만 vs 1200만개로 1/4로 감소한다는 점이 있겠다
    - 이는 논문에도 나와 있지만 InceptionModule의 `5*5` 필터를 `3*3` 필터 2개로 바꿔서 연산하기 때문인 것 같음

### 2. 모델 테스트
- `100*100`에 손글씨를 그려 넣어 추론을 시도해 봄
    - 결과는 그리 성공적이지 못하다 
- `60*60`으로 도화지를 바꿔도 마찬가지 
    - 딱 맞는 결과가 나온 경우는 추론 2에서 1번 나오긴 함(2번째로 높은 확률)
    - 글씨 굵기를 키워봤는데, 별반 다르진 않은 듯?
- 원인 분석
    - 기존 텍스트 이미지를 확대하는 과정에서 가우시안 필터를 적용했음 
    - 근데 내 `도화지는 0 아니면 1으로만 구성`됨
    - 모델 학습 시 `이진화 & RandomZoom & RandomRotation` 적용해볼만 한 듯

## 220705
1. 모델 만들기 : [다른 논문](https://scienceon.kisti.re.kr/commons/util/originalView.do?cn=JAKO201630762630914&oCn=JAKO201630762630914&dbt=JAKO&journal=NJOU00431883)
    - `GlobalAveragePooling`이 문제였나..? 
        - 저거를 `AveragePooling2D(7*7, 1, padding='valid')` -> `Conv2D((1,1), 128)` -> `Flatten()` -> `Dense(1024)` -> 
        `Dropout(0.7)` -> `Dense(num_classes = 2350)` 으로 하니까 올라감
        - 원래 했던 모델에 적용해봐야겠다
        - 물론 원래 모델의 인셉션 층이 9개여서 Gradient Vanishing이 일어난 걸 수도 있음
            - 너무 깊음 + 중간 층이 없으니까
            - 근데 논문에선 된다고 했으니까 내 설계문제일 가능성이 더 큼
        - 학습 잘 되고 있는 듯



## 220704
1. 모델 만들기 - 근데 코드가 나와 있는 게 아니라서 직접 구현해야 함
    - 논문과 조건을 동일하게 맞춰야겠다 
        - 훈련 시 `batch_size`를 크게(`1024`) 하니까 램 할당량 초과로 계속 리셋됨
    - 지금까지는 `15 * 15` 이미지 & 데이터 전체를 썼는데, 이미지가 너무 작고 데이터는 너무 많음(500만개)
    - 논문과 조건을 맞추기 위해 `60 * 60` 이미지로 바꾸고 label당 100개만 이용하겠다
        - 원래 변환을 모든 데이터에서 다 하고 100개씩만 꺼내 쓸 생각이었으나, 데이터 크기가 60GB에 달하므로 코랩에 못 올림
        - 그래서 label당 100개 씩만 변환하기 위해 가져오는 파이썬 코드(`main2/phd08_to_npy.py`)를 수정

2. 코랩 램 이슈.. label 당 데이터 50개로 줄이거나 모델 크기를 줄여야 하는데 데이터부터 줄여서 진행해봄 (완)



## 220702 
1. 넘파이 데이터 불러와 메모리에 올리기 (완) & 넘파이 파일 구글 드라이브에 저장
    - `np.concatenate` 시도 : 4만개 넘어가니까 확 느려짐
        - 검색 결과 : arr 기반 알고리즘의 `resize`가 일어나면, 내부의 모든 요소를 복사해야 함
        - 전체 array 사이즈를 알 수 있기 때문에 `np.empty((size), dtype)`으로 미리 arr을 넣고 값을 넣는 방식으로 해결
        - 생각보다 빠름
    - 참고 : `plt.imshow()`는 `np.float16`에서 사용이 안된다 (버그인지는 몰?루)
        - 그래서 `plt.imshow()`로 시각화하고 싶다면 해당 array를 `np.array(arr, dtype=np.float32)`를 넣어서 확인할 것
2. `minmaxscaler` 적용 (완)


## 220701
1. 모델 만들기 (2) : (코랩에서 진행) csv 파일을 이용해 모델 생성
    - 시각화했을 때 각 글자는 7 ~ 13개가 있는 듯 보였으나... 1개 있는 글자도 있다. 아..
    - 교훈 ) 본격적인 프로젝트 시작 전에 데이터부터 파악해둘 필요가 있다.
    - Stratify를 위해 <b>데이터 갯수가 5개보다 적다면 제외</b>하겠음 (완료)
    - 좋은 성능을 기대하기는 힘들어진 것 같고, 일단 모델을 완성해서 적용하는 것까지 구현해보자
    - 구현에 의의를 두기로 했으나...

2. 전처리들 끝내고(LabelEncoder, Pandas(`.apply` 등..)) `main1.py`에서 했던 모델을 거의 그대로 가져오고 마지막 분류 층의 노드 수만 11117개로 늘렸으나 학습률이 절망적임 (0.0001 수준)
    - <b>모델과 데이터 모두 바꿀 필요성</b>이 있어 보임
    - 모델은 [이 논문](https://scienceon.kisti.re.kr/commons/util/originalView.do?cn=JAKO201823955287871&oCn=JAKO201823955287871&dbt=JAKO&journal=NJOU00292001)을 참고할 예정
    - DB는 [PE92](https://www.koreascience.or.kr/article/CFKO199229013564134.pdf)을 볼 예정이었으나

3. DB가 `hdu1` 확장자명으로 저장되어 있는데 이걸 파이썬에 담을 수가 없었다(`UTF-8`, `CP949` 코덱 모두 디코드에러가 뜸)
    - 바이너리로 읽은 뒤 `\OOO` 값이나 `\OO`값을 `decode()` 메소드나 `list()`에 담아서 볼 수 있었는데, 아무래도 별도의 방법이 필요한 듯 함(리스트에 담은 뒤 16 * 16으로 `np.reshape`를 해봤으나 글자가 아니라 이상한 모양이 나옴)

4. 그래서 다른 DB인 `phd08`을 사용, 텍스트 파일로 저장되어 있다.
    - 이걸 누군가가 넘파이 혹은 png 파일로 자동으로 저장할 수 있게 [프로그램](https://github.com/sungjunyoung/phd08-conversion)을 짜 둔게 있었다. 
    - 단 2017년에 올라온 코드라 더 이상 지원하지 않는 함수 `scipy.misc.imresize`가 있어서, 이를 `np.array(PIL.Image.fromarray(arr).resize()` 함수로 바꿔서 사용했다.
    - 이 데이터를 `15 * 15`로 바꿔서 넘파이로 저장해서 사용할 예정이다. 넘파이로 잘 불러와지는지까지 확인하고 오늘은 마무리할 예정.

## 220629
1. 모델 만들기 (1) : json 파일 & 이미지 파일 -> csv 파일로 저장
    - 픽셀의 각 값을 별도의 column으로 해서 저장하는 게 낫지 않을까.. 그렇게 분리해서 csv 파일에 저장할 수 있을 듯
    - 아예 정규화까지 해버리는 것도 좋을 듯?


## 220628
1. MNIST 모델 - INPUT에 다양한 변화를 주며 훈련시키기 (완)
- 데이터 증강 층만 추가한 `model_220628.h5` 학습 (`RandomZoom`, `RandomRotation` 층 모델에 추가)
- 원래는 MNIST 이미지를 `100*100`으로 Resizing해서 학습시키려 했으나, 코랩에서 OOM(GPU 메모리 부족) 에러가 뜨기도 했고, 검색 결과 "이미지 확대를 굳이 해야 됨?"이라는 의견과 "이미지 확대는 추가적인 정보를 얻지 못하면서도 요구 메모리가 증가함"이라는 의견을 접했음.

2. 한글 or 일본어 손글씨 추론 모델 만들기
- 일단 json 파일 파싱해서 손글씨 + 음절 데이터를 추리는 것 까지는 성공함 (dict에 저장 : `example_json_parsing.py`)

    ### 앞으로 할 일
    - 이미지 크기가 제각각임 : 통일 시켜줄 필요가 있음
        - `100 * 100` 시도해보고, 메모리가 안된다 싶으면 이미지 크기를 더 낮춰서 진행.
    - dict의 key는 파일(`image_id`), value는 target 값임(해당 이미지가 나타내는 글자)
    - 이걸로 모델 만들어서 분류시키면 될듯

## 220627
1. 출력할 때 확률이 높은 3개 출력하기
    - `np.argsort()` 라니.. 누가 알았겠는가? (몇 시간 헤멤) 역시 라이브러리 문서가 최고다.
    
    ### 앞으로 할 일
        1. 모델 재훈련 : 글씨가 작아지는 경우도 잘 파악해야 하지 않을까..
        2. 한글, 일본어(가나, 한자?)로 넘어가기로 한다.

## 220624
1. 구현 자체는 성공했으나, 모델의 필기체 인식 성능이 매우 떨어짐

    ### 예측 성능에 관한 분석
    - 짐작 가는 오류 원인은 2가지가 있다.
    - 1. mnist 이미지는 28 * 28인데, 그림판은 100 * 100을 만든 뒤 28 * 28로 축소하는 방식임 : 손실되는 정보가 있을 것
    - 2. mnist 이미지의 배경은 흑색, 글씨는 백색인데 그림판의 배경은 백색, 글씨는 흑색임
    - 실제로 테스트해보니, (체감상) 크기도 영향이 있지만, 색상이 오류에 기여하는 바가 더 커보임

2. 모델 재훈련(`model_220624.h5`)
    - 인풋 데이터의 배경색과 글자 색만 반전, 크기는 `28 * 28` 유지함
    - 실행 결과 글씨가 화면을 꽉 채울 정도가 되면 잘 인식함
    - 한편 크기가 어느 정도 작다면 출력에 오류가 있는 경우가 많음
    - 이는 그림판에 그린 손글씨를 축소시켜서 추론 모델에 넣는 과정에서 정보들이 사라지는 것으로 보임


